# Model Configuration for Llama-2-7B
# Meta's Llama-2 7B model for lexical simplification

model:
  name: "Llama-2-7B"
  path: "meta-llama/Llama-2-7b"
  max_length: 2048
  device: "cuda"
  torch_dtype: "bfloat16"
  load_in_8bit: true
  load_in_4bit: false

training:
  batch_size: 1
  learning_rate: 0.0
