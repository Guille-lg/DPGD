# Model Configuration for Mistral-7B-v0.1
# Mistral AI's Mistral 7B v0.1 model for lexical simplification

model:
  name: "Mistral-7B-v0.1"
  path: "mistralai/Mistral-7B-v0.1"
  max_length: 2048
  device: "cuda"
  torch_dtype: "bfloat16"
  load_in_8bit: true
  load_in_4bit: false

training:
  batch_size: 1
  learning_rate: 0.0
