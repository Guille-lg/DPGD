# Model Configuration for Gemma-7B
# Google's Gemma 7B model for lexical simplification

model:
  name: "Gemma-7B"
  path: "google/gemma-7b"
  max_length: 2048
  device: "cuda"
  torch_dtype: "bfloat16"
  load_in_8bit: true
  load_in_4bit: false

training:
  batch_size: 1
  learning_rate: 0.0
